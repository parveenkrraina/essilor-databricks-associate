{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f318a951-cebb-4dc5-b20e-8303b88892b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col, lit, coalesce\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d75f4b-6329-40dc-b092-9d9f957b0ceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df =spark.read.option(\"header\", True)\\\n",
    "               .option(\"escape\", '\"')\\\n",
    "               .option(\"quote\", '\"')\\\n",
    "               .option(\"multiLine\", True)\\\n",
    "               .csv(\"dbfs:/FileStore/shared_uploads/parveen.r@live.com/sales.csv\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e130f56-c33c-4c88-916c-fa67d97a7050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"dbfs:/FileStore/shared_uploads/parveen.r@live.com/sales.csv\")\n",
    "\n",
    "print(\"Loaded sales.csv file:\")\n",
    "sales_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38dc0e5a-d780-4e4b-83ae-1e7c787a685d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(sales_df.select(\"ProductMetadata\").first()[\"ProductMetadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c4ace3-50c2-408f-b536-756ce01e714d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df.select(\"ProductMetadata\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128a5e23-b288-4a9a-b7b2-21946f7e4115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Write as Delta table (overwrite if exists)\n",
    "sales_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"sales_delta_demo\")\n",
    "\n",
    "print(\"sales_delta_demo Delta table created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446b819c-6c57-49b2-8fcc-9dbaa70900ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Create SQL UDF to uppercase CustomerName\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION to_upper_case(str STRING) RETURNS STRING\n",
    "RETURN UPPER(str)\n",
    "\"\"\")\n",
    "print(\"SQL UDF 'to_upper_case' created.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "976b2281-e1e9-4c4c-b012-49a06213d6e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Create SQL UDF to Reverse CustomerName\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION to_reverse(str STRING) RETURNS STRING\n",
    "RETURN Reverse(str)\n",
    "\"\"\")\n",
    "print(\"SQL UDF 'to_reverse' created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "845c1cb7-d316-4a1d-9249-9c605d12018f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT CustomerName, to_upper_case(CustomerName) AS CustomerName_Upper, to_reverse(CustomerName) AS CustomerName_Reverse FROM sales_delta_demo LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21be1042-f411-4006-ba03-99c4856c38e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Create SQL UDF to find the Demand\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION demand(qty INT) RETURNS STRING\n",
    "RETURN CASE\n",
    "    WHEN qty<2 THEN 'Low'\n",
    "    WHEN qty BETWEEN 2 and 6 THEN 'Medium'\n",
    "    WHEN qty>=10 THEN 'High'\n",
    "END;\n",
    "\"\"\")\n",
    "print(\"SQL UDF 'demand' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c1bab44-44bc-4ccd-aef8-43940d8f51d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select Quantity, demand(Quantity) as Demand from sales_delta_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2700b3-9832-4f9a-bdd2-7d8f228ca7f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Parse JSON in ProductMetadata column\n",
    "json_schema = StructType([\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"warranty\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35f994ad-2b53-4644-b504-ee01b574bd44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean ProductMetadata strings (remove leading/trailing quotes and fix escapes)\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "sales_clean = sales_df.withColumn(\n",
    "    \"ProductMetadata_clean\",\n",
    "    regexp_replace(col(\"ProductMetadata\"), '^\"+|\"+$', '')\n",
    ").withColumn(\n",
    "    \"ProductMetadata_clean\",\n",
    "    regexp_replace(col(\"ProductMetadata_clean\"), '\"\"', '\"')\n",
    ")\n",
    "\n",
    "df_parsed = sales_clean.withColumn(\"ProductDetails\", from_json(col(\"ProductMetadata_clean\"), json_schema))\n",
    "\n",
    "df_parsed.select(\"SalesOrderNumber\", \"CustomerName\", \"ProductDetails.color\", \"ProductDetails.warranty\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928c1671-51c8-42cd-aafb-f030a2c37937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Schema Evolution: Add a new column 'Discount' with default value 0.1\n",
    "df_with_discount = df_parsed.withColumn(\"Discount\", lit(0.1))\n",
    "\n",
    "df_with_discount.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"sales_delta_demo\")\n",
    "\n",
    "print(\"Added 'Discount' column using schema evolution.\")\n",
    "\n",
    "spark.table(\"sales_delta_demo\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63d3a042-8231-4185-a898-76806e92bc41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Time Travel: Query previous version of the table (version 0)\n",
    "print(\"Time travel query to version 0:\")\n",
    "spark.sql(\"SELECT * FROM sales_delta_demo VERSION AS OF 0 LIMIT 10\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd331704-1376-4f15-82ec-fd10681ba4a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. Optimize table and Z-order by CustomerName\n",
    "spark.sql(\"OPTIMIZE sales_delta_demo ZORDER BY (CustomerName)\")\n",
    "\n",
    "print(\"OPTIMIZE with ZORDER completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7529622631479832,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SQL UDFs, JSON handling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}