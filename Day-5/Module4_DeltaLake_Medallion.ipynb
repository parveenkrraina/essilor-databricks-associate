{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87968016-61f0-41f3-a763-1b0a7e30f15c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 4: Managing Data with Delta Lake and Medallion â€” Hands-on Lab\n",
    "\n",
    "**Datasets (upload to `dbfs:/FileStore/delta_lab/input/`):**\n",
    "- `sales.csv`\n",
    "- `products.csv`\n",
    "- `customer_demographics.csv`\n",
    "\n",
    "**Table names (Unity Catalog or Hive metastore):**\n",
    "- `delta_lab.bronze_sales`, `delta_lab.bronze_products`, `delta_lab.bronze_customers`\n",
    "- `delta_lab.silver_sales`, `delta_lab.silver_products`, `delta_lab.silver_customers`\n",
    "- `delta_lab.gold_sales_item`, `delta_lab.gold_sales_customer`\n",
    "\n",
    "> If using the Hive metastore, drop the catalog prefix (e.g., use `bronze_sales`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f915b32-783f-43c1-840d-877b39ae5821",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1) Setup: Paths & Helper Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe3ac41-2c6c-49aa-8a28-30f845993d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Python cell: set DBFS paths and create directories\n",
    "base_path = \"dbfs:/FileStore/delta_lab\"\n",
    "input_path = f\"{base_path}/input\"\n",
    "bronze_path = f\"{base_path}/bronze\"\n",
    "silver_path = f\"{base_path}/silver\"\n",
    "gold_path = f\"{base_path}/gold\"\n",
    "chk_path = f\"{base_path}/checkpoints\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "dbutils.fs.mkdirs(base_path)\n",
    "dbutils.fs.mkdirs(input_path)\n",
    "dbutils.fs.mkdirs(bronze_path)\n",
    "dbutils.fs.mkdirs(silver_path)\n",
    "dbutils.fs.mkdirs(gold_path)\n",
    "dbutils.fs.mkdirs(chk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48866553-60d5-4436-a874-80977bbe391c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2) Ingest CSVs to Bronze as Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ffecf61-000a-4a29-8e4f-93a36d98fc63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType, DateType\n",
    "\n",
    "# Define explicit schemas for enforcement\n",
    "sales_schema = StructType([\n",
    "    StructField(\"SalesOrderNumber\", StringType(), True),\n",
    "    StructField(\"SalesOrderLineNumber\", IntegerType(), True),\n",
    "    StructField(\"OrderDate\", TimestampType(), True),\n",
    "    StructField(\"CustomerName\", StringType(), True),\n",
    "    StructField(\"EmailAddress\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"UnitPrice\", DoubleType(), True),\n",
    "    StructField(\"TaxAmount\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "products_schema = StructType([\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"ProductName\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"UnitPrice\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField(\"CustomerId\", StringType(), True),\n",
    "    StructField(\"CustomerName\", StringType(), True),\n",
    "    StructField(\"EmailAddress\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "])\n",
    "\n",
    "sales_df = (spark.read\n",
    "            .format(\"csv\")\n",
    "            .schema(sales_schema)\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"timestampFormat\", \"yyyy-MM-dd[ HH:mm:ss]\")\n",
    "            .load(f\"{input_path}/sales.csv\"))\n",
    "\n",
    "products_df = (spark.read\n",
    "               .format(\"csv\")\n",
    "               .schema(products_schema)\n",
    "               .option(\"header\", \"true\")\n",
    "               .load(f\"{input_path}/products.csv\"))\n",
    "\n",
    "customers_df = (spark.read\n",
    "                .format(\"csv\")\n",
    "                .schema(customers_schema)\n",
    "                .option(\"header\", \"true\")\n",
    "                .load(f\"{input_path}/customer_demographics.csv\"))\n",
    "\n",
    "(sales_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{bronze_path}/sales\"))\n",
    "(products_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{bronze_path}/products\"))\n",
    "(customers_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{bronze_path}/customers\"))\n",
    "\n",
    "# Create Bronze managed/external tables\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS delta_lab\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.bronze_sales USING DELTA LOCATION '{bronze_path}/sales'\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.bronze_products USING DELTA LOCATION '{bronze_path}/products'\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.bronze_customers USING DELTA LOCATION '{bronze_path}/customers'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c329ba97-fe26-45e0-9eef-527d92f1460a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3) Schema Enforcement & Evolution (to Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c062eb72-e0bb-4c4f-aa41-643ce534c11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, lit\n",
    "\n",
    "silver_sales_df = (spark.read.format(\"delta\").load(f\"{bronze_path}/sales\")\n",
    "                   .withColumn(\"OrderDate\", col(\"OrderDate\").cast(\"timestamp\"))\n",
    "                   .withColumn(\"OrderDateKey\", to_date(col(\"OrderDate\")).cast(\"date\"))\n",
    "                   .withColumn(\"Amount\", (col(\"Quantity\") * col(\"UnitPrice\") + col(\"TaxAmount\")).cast(\"double\"))\n",
    "                   .select(\"SalesOrderNumber\",\"SalesOrderLineNumber\",\"OrderDate\",\"OrderDateKey\",\n",
    "                           \"CustomerName\",\"EmailAddress\",\"Item\",\"Quantity\",\"UnitPrice\",\"TaxAmount\",\"Amount\"))\n",
    "\n",
    "silver_products_df = (spark.read.format(\"delta\").load(f\"{bronze_path}/products\")\n",
    "                      .select(\"Item\",\"ProductName\",\"Category\",\"UnitPrice\"))\n",
    "\n",
    "silver_customers_df = (spark.read.format(\"delta\").load(f\"{bronze_path}/customers\")\n",
    "                       .select(\"CustomerId\",\"CustomerName\",\"EmailAddress\",\"City\",\"State\",\"Country\"))\n",
    "\n",
    "(silver_sales_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/sales\"))\n",
    "(silver_products_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/products\"))\n",
    "(silver_customers_df.write.format(\"delta\").mode(\"overwrite\").save(f\"{silver_path}/customers\"))\n",
    "\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.silver_sales USING DELTA LOCATION '{silver_path}/sales'\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.silver_products USING DELTA LOCATION '{silver_path}/products'\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.silver_customers USING DELTA LOCATION '{silver_path}/customers'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd77b79c-29ac-4f38-8da7-a80ac3deec85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Auto evolution vs explicit schema (add new column to products)\n",
    "We'll simulate a new column `UnitCost` and upsert with schema evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a85543a1-339b-48e2-9714-5e3dba0ef4a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulate UnitCost column as 70% of UnitPrice\n",
    "products_new_cols_df = (spark.read.format(\"delta\").load(f\"{silver_path}/products\")\n",
    "                        .withColumn(\"UnitCost\", (col(\"UnitPrice\") * lit(0.7)).cast(\"double\")))\n",
    "\n",
    "# Explicit schema merge (per write):\n",
    "(products_new_cols_df.write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"mergeSchema\", \"true\")\n",
    " .save(f\"{silver_path}/products\"))\n",
    "\n",
    "# Or enable auto-merge globally/session:\n",
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe7778c-3f75-40de-a054-88e8880adb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4) Time Travel, History, and Rollback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab4f42a-43ad-4216-bca7-05428bced3b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Capture current version\n",
    "hist_df = spark.sql(\"DESCRIBE HISTORY delta_lab.silver_products\")\n",
    "display(hist_df)\n",
    "\n",
    "# Read a previous version (adjust version number after you inspect history)\n",
    "prev_version = 0  # <-- replace with an actual older version from history\n",
    "silver_products_v0 = (spark.read.format(\"delta\")\n",
    "                      .option(\"versionAsOf\", prev_version)\n",
    "                      .load(f\"{silver_path}/products\"))\n",
    "display(silver_products_v0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e37e49-bbca-4717-a7df-177af3a34abe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5) Build Gold tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e73a2657-b6e6-41a6-89e6-849a85079245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join silver tables for item-level sales\n",
    "silver_sales = spark.read.format(\"delta\").load(f\"{silver_path}/sales\")\n",
    "silver_products = spark.read.format(\"delta\").load(f\"{silver_path}/products\")\n",
    "silver_customers = spark.read.format(\"delta\").load(f\"{silver_path}/customers\")\n",
    "\n",
    "gold_sales_item_df = (silver_sales.alias(\"s\")\n",
    "                      .join(silver_products.alias(\"p\"), \"Item\", \"left\")\n",
    "                      .select(\"s.*\",\"p.ProductName\",\"p.Category\"))\n",
    "\n",
    "(gold_sales_item_df.write.format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .save(f\"{gold_path}/gold_sales_item\"))\n",
    "\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.gold_sales_item USING DELTA LOCATION '{gold_path}/gold_sales_item'\")\n",
    "\n",
    "# Customer-aggregated gold (by day)\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "gold_sales_customer_df = (silver_sales.groupBy(\"OrderDateKey\",\"CustomerName\",\"EmailAddress\")\n",
    "                          .agg(_sum(\"Amount\").alias(\"TotalAmount\"),\n",
    "                               _sum(\"Quantity\").alias(\"TotalQty\")))\n",
    "\n",
    "(gold_sales_customer_df.write.format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .save(f\"{gold_path}/gold_sales_customer\"))\n",
    "\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS delta_lab.gold_sales_customer USING DELTA LOCATION '{gold_path}/gold_sales_customer'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28f641be-2e09-4e13-bb4f-ffb649beb499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6) Optimizations: OPTIMIZE, Z-ORDER, VACUUM, Auto Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba741af4-afcd-4da7-ad7f-d9a5f6289ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# OPTIMIZE + Z-ORDER (Databricks)\n",
    "spark.sql(\"OPTIMIZE delta_lab.gold_sales_item ZORDER BY (Item, OrderDateKey)\")\n",
    "\n",
    "# Table-level Auto Optimize (Databricks)\n",
    "spark.sql(\"ALTER TABLE delta_lab.gold_sales_item SET TBLPROPERTIES (   delta.autoOptimize.optimizeWrite = true,   delta.autoOptimize.autoCompact = true )\")\n",
    "\n",
    "# VACUUM with safe retention (e.g., 168 hours = 7 days)\n",
    "spark.sql(\"VACUUM delta_lab.gold_sales_item RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d15396fb-4130-4ebf-8245-ca07cbc732a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7) Handling Late Arriving Data: MERGE and Streaming\n",
    "We'll simulate late updates using MERGE and demonstrate watermarking in Structured Streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "885fd236-cf4c-4c60-a3fe-8d94772bff5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulate a late-arriving upsert set for silver_sales\n",
    "late_updates = silver_sales.limit(5).withColumn(\"Quantity\", col(\"Quantity\") + 1)\n",
    "\n",
    "# MERGE into Silver\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS delta_lab.silver_sales USING DELTA LOCATION '{loc}'\".format(loc=f\"{silver_path}/sales\"))\n",
    "\n",
    "late_updates.createOrReplaceTempView(\"updates\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO delta_lab.silver_sales AS tgt\n",
    "USING updates AS src\n",
    "ON  tgt.SalesOrderNumber = src.SalesOrderNumber\n",
    "AND tgt.SalesOrderLineNumber = src.SalesOrderLineNumber\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7deae9a3-cb25-4637-87ee-7365a1343cb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8) Validation queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da8d64c5-59fb-43fb-883b-c62edbce177f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM delta_lab.gold_sales_item ORDER BY OrderDateKey DESC, Item LIMIT 20;\n",
    "\n",
    "SELECT * FROM delta_lab.gold_sales_customer ORDER BY OrderDateKey DESC, TotalAmount DESC LIMIT 20;\n",
    "\n",
    "DESCRIBE HISTORY delta_lab.gold_sales_item;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87b80e6-6e1b-49e8-9abe-2a850b066f2a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"current_metastore()\":561},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755246427513}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_metastore()</th></tr></thead><tbody><tr><td>azure:centralus:c98cf59a-7f5b-4696-b5fc-7df83fc1e057</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "azure:centralus:c98cf59a-7f5b-4696-b5fc-7df83fc1e057"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {
             "__autoGeneratedAlias": "true"
            },
            "name": "current_metastore()",
            "nullable": false,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 1
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"__autoGeneratedAlias\":\"true\"}",
         "name": "current_metastore()",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select current_metastore()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7802602812873281,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Module4_DeltaLake_Medallion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}